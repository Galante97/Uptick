{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS PROGRAM TAKES IN A CSV FILE WITH A LIST OF STOCK\n",
    "#ITERATES THROUGH THOSE STOCKS AND GATHERS THE PREVIOUS MONTHS DATA AND SAVES TO GOOGLE SHEETS\n",
    "#USING BARCHART API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS #\n",
    "import time\n",
    "t0 = time.clock()\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.tseries.offsets import BDay\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from copy import copy\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore',category=pd.io.pytables.PerformanceWarning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GOOGLE SHEETS API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'STOCKS': 'AAPL'}, {'STOCKS': 'MSFT'}, {'STOCKS': 'AMZN'}, {'STOCKS': 'VZ'}, {'STOCKS': 'TSLA'}, {'STOCKS': 'GOOGL'}, {'STOCKS': 'INTC'}, {'STOCKS': 'CSCO'}, {'STOCKS': 'ORCL'}, {'STOCKS': 'QCOM'}, {'STOCKS': 'FB'}, {'STOCKS': 'IBM'}]\n"
     ]
    }
   ],
   "source": [
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "\n",
    "# use creds to create a client to interact with the Google Drive API\n",
    "scope = ['https://spreadsheets.google.com/feeds', \n",
    "            'https://www.googleapis.com/auth/drive']\n",
    "creds = ServiceAccountCredentials.from_json_keyfile_name('client_secret.json', scope)\n",
    "client = gspread.authorize(creds)\n",
    "\n",
    "# Find a workbook by name and open the first sheet\n",
    "# Make sure you use the right name here.\n",
    "stockList = client.open(\"STOCKS LIST\").sheet1\n",
    "AAPL_data = client.open(\"AAPL_data\").sheet1\n",
    "VZ_data = client.open(\"VZ_data\").sheet1\n",
    "AMZN_data = client.open(\"AMZN_data\").sheet1\n",
    "MSFT_data = client.open(\"MSFT_data\").sheet1\n",
    "TSLA_data = client.open(\"TSLA_data\").sheet1\n",
    "\n",
    "GOOGL_data = client.open(\"GOOGL_data\").sheet1\n",
    "INTC_data = client.open(\"INTC_data\").sheet1\n",
    "CSCO_data = client.open(\"CSCO_data\").sheet1\n",
    "ORCL_data = client.open(\"ORCL_data\").sheet1\n",
    "QCOM_data = client.open(\"QCOM_data\").sheet1\n",
    "FB_data = client.open(\"FB_data\").sheet1\n",
    "IBM_data = client.open(\"IBM_data\").sheet1\n",
    "\n",
    "\n",
    "# Extract and print all of the values\n",
    "list_of_hashes = stockList.get_all_records()\n",
    "print(list_of_hashes)\n",
    "#setUpSheetsClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================== #\n",
    "# filepath management\n",
    "\n",
    "project_dir = r'/Users/jamesgalante/Documents/College/Semester 7/CPEG498/Uptick/Legacy Data/get past month data/' \n",
    "price_path = project_dir + r'Symbols/'\n",
    "apikey = '0adbf00b462c1acca954a43d94279b92'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##points to our google sheet \"STOCKS LIST\" gets the values and makes it a pandas dataframe to manipulate\n",
    "def getStockList():\n",
    "    sheetsList = stockList.get_all_values()\n",
    "    sheetsList = sheetsList[1:] #remove \"STOCKS\" title\n",
    "    ##print(sheetsList)\n",
    "    sheetsList = flatten(sheetsList)\n",
    "    #print(sheetsList)\n",
    "    #create new df \n",
    "    df = pd.DataFrame({'STOCKS':sheetsList})\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##takes a 2d list and flattens it to 1d\n",
    "def flatten(input):\n",
    "    new_list = []\n",
    "    for i in input:\n",
    "        for j in i:\n",
    "            new_list.append(j)\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting list of stock symbols to var syms\n",
    "syms = getStockList()\n",
    "print(syms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BARCHART API\n",
    "def construct_barChart_url(sym, start_date, freq, interval, api_key=apikey):\n",
    "    '''Function to construct barchart api url'''\n",
    "    \n",
    "    url = 'http://marketdata.websol.barchart.com/getHistory.csv?' +\\\n",
    "            'key={}&symbol={}&type={}&startDate={}&interval={}'.format(api_key, sym, freq, start_date, interval)\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get minute data for the past month for the stocks in the csv file\n",
    "def get_minute_data(start):\n",
    "    print(\"minute data:\")\n",
    "    '''Function to Retrieve <= 3 months of minute data for SP500 components'''\n",
    "    \n",
    "    # This is the required format for datetimes to access the API\n",
    "    # You could make a function to translate datetime to this format\n",
    "    #start = '20181008' #start data doesnt matter as long as its more then a month older\n",
    "    #end = d\n",
    "    freq = 'minutes'   \n",
    "    interval = 10 #minutes\n",
    "    prices = {}\n",
    "    symbol_count = len(syms)\n",
    "    N = copy(symbol_count)\n",
    "    try:\n",
    "        for i, sym in syms.iterrows():\n",
    "            \n",
    "            print(sym[\"STOCKS\"])\n",
    "            api_url = construct_barChart_url(sym[\"STOCKS\"], start, freq, interval , api_key=apikey)\n",
    "            print(api_url)\n",
    "            try:\n",
    "                csvfile = pd.read_csv(api_url, parse_dates=['timestamp'])\n",
    "                csvfile.set_index('timestamp', inplace=True)\n",
    "                prices[sym[\"STOCKS\"]] = csvfile\n",
    "            except:\n",
    "                continue\n",
    "            N -= 1\n",
    "            pct_total_left = (N/symbol_count)\n",
    "            print('{}..[done] | {} of {} symbols collected | percent remaining: {:>.2%}'.format(\\\n",
    "                                                                sym, i, symbol_count, pct_total_left)) \n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "    finally:\n",
    "        pass\n",
    "    px = pd.Panel.from_dict(prices)\n",
    "\n",
    "    return px\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStockDataFromDate(start):\n",
    "    print(syms)\n",
    "    pxx = get_minute_data(start)\n",
    "    # convert timestamps to EST\n",
    "    pxx.major_axis = pxx.major_axis.tz_localize('utc').tz_convert('US/Eastern')\n",
    "    return pxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sends pxx stock data to google sheets. will append pxx to gsheets\n",
    "def sendLocalStockDataToSheets(pxx):\n",
    "    print(\"Sending to google sheets\")\n",
    "    #curr_stock = AAPL_data\n",
    "    for i, sym in syms.iterrows(): #iterate through the panel symbols\n",
    "        for index, row in pxx[sym['STOCKS']].iterrows(): #iterate through each row in each symbol\n",
    "            try:\n",
    "                time.sleep(0.21)\n",
    "                print(\"adding Row\")\n",
    "                if(row.symbol == 'AAPL'):\n",
    "                    AAPL_data.append_row([str(row.name), row.symbol, row.tradingDay, row.open, row.high, row.low, row. close, row.volume])\n",
    "                elif (row.symbol == 'VZ'):\n",
    "                    VZ_data.append_row([str(row.name), row.symbol, row.tradingDay, row.open, row.high, row.low, row. close, row.volume])\n",
    "                elif (row.symbol == 'TSLA'):\n",
    "                    TSLA_data.append_row([str(row.name), row.symbol, row.tradingDay, row.open, row.high, row.low, row. close, row.volume])\n",
    "                elif (row.symbol == 'AMZN'):\n",
    "                    AMZN_data.append_row([str(row.name), row.symbol, row.tradingDay, row.open, row.high, row.low, row. close, row.volume])\n",
    "                elif (row.symbol == 'MSFT'):\n",
    "                    MSFT_data.append_row([str(row.name), row.symbol, row.tradingDay, row.open, row.high, row.low, row. close, row.volume])\n",
    "                elif (row.symbol == 'IBM'):\n",
    "                    IBM_data.append_row([str(row.name), row.symbol, row.tradingDay, row.open, row.high, row.low, row. close, row.volume])\n",
    "                elif (row.symbol == 'FB'):\n",
    "                    FB_data.append_row([str(row.name), row.symbol, row.tradingDay, row.open, row.high, row.low, row. close, row.volume])\n",
    "                elif (row.symbol == 'QCOM'):\n",
    "                    QCOM_data.append_row([str(row.name), row.symbol, row.tradingDay, row.open, row.high, row.low, row. close, row.volume])\n",
    "                elif (row.symbol == 'ORCL'):\n",
    "                    ORCL_data.append_row([str(row.name), row.symbol, row.tradingDay, row.open, row.high, row.low, row. close, row.volume])\n",
    "                elif (row.symbol == 'CSCO'):\n",
    "                    CSCO_data.append_row([str(row.name), row.symbol, row.tradingDay, row.open, row.high, row.low, row. close, row.volume])\n",
    "                elif (row.symbol == 'INTC'):\n",
    "                    INTC_data.append_row([str(row.name), row.symbol, row.tradingDay, row.open, row.high, row.low, row. close, row.volume])\n",
    "                elif (row.symbol == 'GOOGL'):\n",
    "                    GOOGL_data.append_row([str(row.name), row.symbol, row.tradingDay, row.open, row.high, row.low, row. close, row.volume])\n",
    "                    \n",
    "            except:\n",
    "                print(\"Error adding row!\", row)\n",
    "                continue\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#updates the google sheets tables\n",
    "def updateSheetsWithLatest():\n",
    "    print(\"updating:\")\n",
    "    serverData = AAPL_data.get_all_values() #only gets the date of AAPL since they should all be uniform\n",
    "    lastRowOnServer = serverData[-1]\n",
    "    lastTimestampOnServer = lastRowOnServer[2]\n",
    "    lastTimestampOnServer_noDash = lastTimestampOnServer.replace(\"-\", \"\") #remove the dast\n",
    "    \n",
    "    localData = getStockDataFromDate(lastTimestampOnServer_noDash) \n",
    "    \n",
    "    #localData = getStockDataFromDate('20180901') \n",
    "\n",
    "    print(type(localData))\n",
    " #   localData['AAPL'] = localData['AAPL'][localData['AAPL'].tradingDay != lastTimestampOnServer] #removes any duplicate\n",
    " #   localData['MSFT'] = localData['MSFT'][localData['MSFT'].tradingDay != lastTimestampOnServer] #removes any duplicate\n",
    " #   localData['AMZN'] = localData['AMZN'][localData['AMZN'].tradingDay != lastTimestampOnServer] #removes any duplicate\n",
    " #   localData['VZ'] = localData['VZ'][localData['VZ'].tradingDay != lastTimestampOnServer] #removes any duplicate\n",
    " #   localData['TSLA'] = localData['TSLA'][localData['TSLA'].tradingDay != lastTimestampOnServer] #removes any duplicate\n",
    " #   localData['IBM'] = localData['IBM'][localData['IBM'].tradingDay != lastTimestampOnServer] #removes any duplicate\n",
    " #   localData['FB'] = localData['FB'][localData['FB'].tradingDay != lastTimestampOnServer] #removes any duplicate\n",
    " #   localData['QCOM'] = localData['QCOM'][localData['QCOM'].tradingDay != lastTimestampOnServer] #removes any duplicate\n",
    " #   localData['ORCL'] = localData['ORCL'][localData['ORCL'].tradingDay != lastTimestampOnServer] #removes any duplicate\n",
    " #   localData['CSCO'] = localData['CSCO'][localData['CSCO'].tradingDay != lastTimestampOnServer] #removes any duplicate\n",
    " #   localData['INTC'] = localData['INTC'][localData['INTC'].tradingDay != lastTimestampOnServer] #removes any duplicate\n",
    " #   localData['GOOGL'] = localData['GOOGL'][localData['GOOGL'].tradingDay != lastTimestampOnServer] #removes any duplicate\n",
    "\n",
    "    \n",
    "    sendLocalStockDataToSheets(localData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main():\n",
    "    #getStockDataFromDate('20180932')\n",
    "    updateSheetsWithLatest() \n",
    "    #sendLocalStockDataToSheets()\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is i: 1\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "print(\"this is i:\",i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
