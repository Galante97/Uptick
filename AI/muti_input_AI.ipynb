{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MULTI PRECISION A.I:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Imports:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import Timestamp\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "\n",
    "#to plot within notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#setting figure size\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 20,10\n",
    "\n",
    "#for normalizing data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "import google_sheets_api as sheet #connection to server\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AI Librarys \n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Stock Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllSheets():\n",
    "    sheet_aapl = sheet.AAPL_data.get_all_values() \n",
    "    sheet_amzn = sheet.AMZN_data.get_all_values()\n",
    "    sheet_csco = sheet.CSCO_data.get_all_values()\n",
    "    sheet_fb = sheet.FB_data.get_all_values()\n",
    "    sheet_googl = sheet.GOOGL_data.get_all_values()\n",
    "    sheet_IBM = sheet.IBM_data.get_all_values()\n",
    "    sheet_intc = sheet.INTC_data.get_all_values()\n",
    "    sheet_msft = sheet.MSFT_data.get_all_values()\n",
    "    sheet_orcl = sheet.ORCL_data.get_all_values()\n",
    "    sheet_qcom = sheet.QCOM_data.get_all_values()\n",
    "    sheet_tsla = sheet.TSLA_data.get_all_values()\n",
    "    sheet_vz = sheet.VZ_data.get_all_values()\n",
    "\n",
    "    sheet_aapl = sheet_aapl[1:] #remove column names title\n",
    "    sheet_amzn = sheet_amzn[1:] #remove column names title\n",
    "    sheet_csco = sheet_csco[1:] #remove column names title\n",
    "    sheet_fb = sheet_fb[1:] #remove column names title\n",
    "    sheet_googl = sheet_googl[1:] #remove column names title\n",
    "    sheet_intc = sheet_intc[1:] #remove column names title\n",
    "    sheet_msft = sheet_msft[1:] #remove column names title\n",
    "    sheet_IBM = sheet_IBM[1:] #remove column names title\n",
    "    sheet_orcl = sheet_orcl[1:] #remove column names title\n",
    "    sheet_qcom = sheet_qcom[1:] #remove column names title\n",
    "    sheet_tsla = sheet_tsla[1:] #remove column names title\n",
    "    sheet_vz = sheet_vz[1:] #remove column names title\n",
    "\n",
    "\n",
    "    \n",
    "    AAPL_data = pd.DataFrame(sheet_aapl, columns = ['timestamp','symbol','tradingDay','open','high','low','close','volume']) \n",
    "    AMZN_data = pd.DataFrame(sheet_amzn, columns = ['timestamp','symbol','tradingDay','open','high','low','close','volume']) \n",
    "    CSCO_data = pd.DataFrame(sheet_csco, columns = ['timestamp','symbol','tradingDay','open','high','low','close','volume']) \n",
    "    FB_data = pd.DataFrame(sheet_fb, columns = ['timestamp','symbol','tradingDay','open','high','low','close','volume']) \n",
    "    GOOGL_data = pd.DataFrame(sheet_googl, columns = ['timestamp','symbol','tradingDay','open','high','low','close','volume']) \n",
    "    INTC_data = pd.DataFrame(sheet_intc, columns = ['timestamp','symbol','tradingDay','open','high','low','close','volume']) \n",
    "    MSFT_data = pd.DataFrame(sheet_msft, columns = ['timestamp','symbol','tradingDay','open','high','low','close','volume']) \n",
    "    IBM_data = pd.DataFrame(sheet_IBM, columns = ['timestamp','symbol','tradingDay','open','high','low','close','volume']) \n",
    "    ORCL_data = pd.DataFrame(sheet_orcl, columns = ['timestamp','symbol','tradingDay','open','high','low','close','volume']) \n",
    "    QCOM_data = pd.DataFrame(sheet_qcom, columns = ['timestamp','symbol','tradingDay','open','high','low','close','volume']) \n",
    "    TSLA_data = pd.DataFrame(sheet_tsla, columns = ['timestamp','symbol','tradingDay','open','high','low','close','volume']) \n",
    "    VZ_data = pd.DataFrame(sheet_vz, columns = ['timestamp','symbol','tradingDay','open','high','low','close','volume']) \n",
    "\n",
    "\n",
    "    return [AAPL_data, AMZN_data, CSCO_data, FB_data, GOOGL_data, INTC_data, MSFT_data, IBM_data, ORCL_data, QCOM_data, TSLA_data, VZ_data]\n",
    "\n",
    "    \n",
    "all_stock_data = getAllSheets()  ##THIS VAR HOLDS ALL OF THE STOCK DATA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reformat Server Data to Fit A.I. Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AAPL = all_stock_data[0] #AAPL\n",
    "df_AMZN = all_stock_data[1] #AMZN\n",
    "df_CSCO = all_stock_data[2] #CSCO\n",
    "df_FB = all_stock_data[3] #FB\n",
    "df_GOOGL = all_stock_data[4] #GOOGL\n",
    "df_INTC = all_stock_data[5] #INTC\n",
    "df_MSFT = all_stock_data[6] #MSFT\n",
    "df_IBM = all_stock_data[7] #IBM\n",
    "df_ORCL = all_stock_data[8] #ORCL\n",
    "df_QCOM = all_stock_data[9] #QCOM\n",
    "df_TLSA = all_stock_data[10] #TSLA\n",
    "df_VZ = all_stock_data[11] #VZ\n",
    "\n",
    "all_stock_dataframes = [df_AAPL, df_AMZN, df_CSCO, df_FB, df_GOOGL, df_INTC, df_MSFT, df_IBM, df_ORCL, df_QCOM, df_TLSA, df_VZ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "\n",
    "for df in all_stock_dataframes:    \n",
    "    df['open'] = df['open'].astype(float)\n",
    "    df['high'] = df['high'].astype(float)\n",
    "    df['low'] = df['low'].astype(float)\n",
    "    df['close'] = df['close'].astype(float)\n",
    "    df['volume'] = df['volume'].astype(int)\n",
    "    for index, row in df.iterrows():    \n",
    "        if row['timestamp'].endswith('-05:00'):\n",
    "            df['timestamp'].iloc[index] = row['timestamp'][:-6]\n",
    "               \n",
    "    df.index = df['timestamp']\n",
    "    print(count, \"of \", len(all_stock_dataframes), \"stock dataframes successfully reformatted\")\n",
    "    count+=1\n",
    "\n",
    "print(\"All data successfully reformatted!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rows = df_AAPL.count()\n",
    "print(total_rows['close'] +1)\n",
    "\n",
    "training_data_split = int(total_rows['close']*0.6) #80% of the data becomes train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_ticker(ticker):\n",
    "    if (ticker == 'AAPL'):\n",
    "        return df_AAPL\n",
    "    if (ticker == 'AMZN'):\n",
    "        return df_AMZN\n",
    "    if (ticker == 'CSCO'):\n",
    "        return df_CSCO\n",
    "    if (ticker == 'FB'):\n",
    "        return df_FB\n",
    "    if (ticker == 'GOOGL'):\n",
    "        return df_GOOGL\n",
    "    if (ticker == 'INTC'):\n",
    "        return df_INTC\n",
    "    if (ticker == 'MSFT'):\n",
    "        return df_MSFT\n",
    "    if (ticker == 'IBM'):\n",
    "        return df_IBM\n",
    "    if (ticker == 'ORCL'):\n",
    "        return df_ORCL\n",
    "    if (ticker == 'QCOM'):\n",
    "        return df_QCOM\n",
    "    if (ticker == 'TLSA'):\n",
    "        return df_TLSA\n",
    "    if (ticker == 'VZ'):\n",
    "        return df_VZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LONG SHORT TERM MEMORY MACHINE LEARNING (MULIPLE INPUTS):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_prediction_multi_precision3(symbol, sensitivity, prediction_date , data_points):\n",
    "    totalInputs = len(data_points)\n",
    "    print(\"stock symbol:\",symbol)\n",
    "    print(\"sensitivity:\",sensitivity)\n",
    "    print(\"Date to be predicted: \", prediction_date)\n",
    "    x = datetime.datetime(prediction_date[0:4], 3, 23)\n",
    "    print(x)\n",
    "    print(x.weekday())\n",
    "\n",
    "    print(\"total Inputs:\",totalInputs)\n",
    "    \n",
    "    \n",
    "    current_stock_df = determine_ticker(symbol)\n",
    "    \n",
    "    #creating dataframe\n",
    "    data = current_stock_df.sort_index(ascending=True, axis=0)\n",
    "    new_data = pd.DataFrame(index=range(0,len(current_stock_df)),columns=['timestamp', data_points[0], data_points[1],data_points[2],data_points[3],data_points[4]])\n",
    "\n",
    "    \n",
    "    #creating a new_data DF for manipulation\n",
    "    for i in range(0,len(data)):\n",
    "        new_data['timestamp'][i] = data['timestamp'][i]\n",
    "        new_data[data_points[0]][i] = data[data_points[0]][i]\n",
    "        new_data[data_points[1]][i] = data[data_points[1]][i]\n",
    "        new_data[data_points[2]][i] = data[data_points[2]][i]\n",
    "        new_data[data_points[3]][i] = data[data_points[3]][i]\n",
    "        new_data[data_points[4]][i] = data[data_points[4]][i]\n",
    "\n",
    "        \n",
    "    #setting index to timestamp \n",
    "    new_data.index = new_data.timestamp\n",
    "    new_data.drop('timestamp', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "    #creating train and test sets\n",
    "    dataset = new_data.values \n",
    "    \n",
    "    \n",
    "    train = dataset[0:training_data_split,:] #TRAINGING 80%\n",
    "    valid = dataset[training_data_split:,:] #DATA POINTS TO BE PREDICTED 20%\n",
    "    \n",
    "    #converting dataset into x_train and y_train\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))   #NORMALIZARION between O and 1 of the data\n",
    "    scaled_data = scaler.fit_transform(dataset)   #FITS OUR DATA SET TO THE NORMALIZATION BETWEEN ONE AND ZERO\n",
    "      \n",
    "    #Spliting the data into X train and Y Train\n",
    "    x_train, y_train = [], []\n",
    "    for i in range(50,len(train)):\n",
    "        x_train.append(scaled_data[i-50:i,:])\n",
    "        y_train.append(scaled_data[i,1])\n",
    "\n",
    "    \n",
    "    x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "\n",
    "\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],totalInputs))  \n",
    "  \n",
    "    print(\"x_train.shape:\", x_train.shape)\n",
    "  #  print(\"x_train.shape:\", x_train)\n",
    "    \n",
    "    # create and fit the LSTM network\n",
    "    model = Sequential() \n",
    "    print(type(model))\n",
    "\n",
    "    model.add(LSTM(units=50, return_sequences=True, input_shape=(x_train.shape[1],totalInputs))) #2 input\n",
    "    model.add(LSTM(units=30, return_sequences=True))\n",
    "    model.add(LSTM(units=30))\n",
    "    model.add(Dense(units=1))\n",
    "    model.summary()\n",
    "    \n",
    "    print(x_train.shape)\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model.fit(x_train, y_train, epochs=sensitivity, batch_size=32)  #EPOCHS determine sensitivity\n",
    "    model.summary()\n",
    "    \n",
    "    #predicting values, using past 50 from the train data\n",
    "    inputs = new_data[len(new_data) - len(valid) - 50:].values\n",
    "    \n",
    "    inputs = inputs.reshape(-1,totalInputs)   \n",
    "    inputs  = scaler.transform(inputs)\n",
    "\n",
    "    X_test = []\n",
    "    for i in range(50,inputs.shape[0]):\n",
    "        X_test.append(inputs[i-50:i,:])\n",
    "   \n",
    "\n",
    "    X_test = np.array(X_test)\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0],X_test.shape[1],totalInputs))\n",
    "\n",
    "    predictons = model.predict(X_test) #PREDICTIONS\n",
    "\n",
    "    formated_preds = np.zeros((predictons.shape[0],predictons.shape[1]+(totalInputs-1)))\n",
    "    formated_preds[:,:-1] = predictons\n",
    "\n",
    "    predictons = scaler.inverse_transform(formated_preds) #DE NORMALIZARION\n",
    "   \n",
    "\n",
    "\n",
    "    #for plotting\n",
    "    train = new_data[:training_data_split]\n",
    "    valid = new_data[training_data_split:]\n",
    "   \n",
    "    valid['Predictions'] = predictons[: , :1]\n",
    "    plt.figure(figsize=(15,10))\n",
    "\n",
    "\n",
    "    plt.plot(train[data_points[0]], 'b')\n",
    "    plt.plot(valid[[data_points[0],'Predictions']])\n",
    "\n",
    "    plt.xlabel('timestamp')\n",
    "    plt.ylabel(data_points[0])\n",
    "    plt.title(symbol) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stock symbol: AAPL\n",
      "sensitivity: 10\n",
      "Date to be predicted:  20190304\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-30991409b5e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mLSTM_prediction_multi_precision3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'AAPL'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20190304\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'open'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'close'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'low'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'high'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'volume'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#LSTM_prediction_multi_precision3('AMZN', 30, ['open','close','low','high','volume'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#LSTM_prediction_multi_precision3('CSCO', 30, ['open','close','low','high','volume'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#LSTM_prediction_multi_precision3('FB', 30, ['open','close','low','high','volume'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#LSTM_prediction_multi_precision3('GOOGL', 30, ['open','close','low','high','volume'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-d744b8ce06bc>\u001b[0m in \u001b[0;36mLSTM_prediction_multi_precision3\u001b[0;34m(symbol, sensitivity, prediction_date, data_points)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sensitivity:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msensitivity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Date to be predicted: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_date\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction_date\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m23\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweekday\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "LSTM_prediction_multi_precision3('AAPL', 10, 20190304, ['open','close','low','high','volume'])\n",
    "#LSTM_prediction_multi_precision3('AMZN', 30, ['open','close','low','high','volume'])\n",
    "#LSTM_prediction_multi_precision3('CSCO', 30, ['open','close','low','high','volume'])\n",
    "#LSTM_prediction_multi_precision3('FB', 30, ['open','close','low','high','volume'])\n",
    "#LSTM_prediction_multi_precision3('GOOGL', 30, ['open','close','low','high','volume'])\n",
    "#LSTM_prediction_multi_precision3('INTC', 30, ['open','close','low','high','volume'])\n",
    "#LSTM_prediction_multi_precision3('MSFT', 30, ['open','close','low','high','volume'])\n",
    "#LSTM_prediction_multi_precision3('IBM', 30, ['open','close','low','high','volume'])\n",
    "#LSTM_prediction_multi_precision3('ORCL', 30, ['open','close','low','high','volume'])\n",
    "#LSTM_prediction_multi_precision3('QCOM', 30, ['open','close','low','high','volume'])\n",
    "#LSTM_prediction_multi_precision3('TLSA', 30, ['open','close','low','high','volume'])\n",
    "#LSTM_prediction_multi_precision3('VZ', 30, ['open','close','low','high','volume'])\n",
    "\n",
    "#Stock OPTIONS: AAPL, AMZN, CSCO, FB, GOOGL,INTC, MSFT, IBM, ORCL, QCOM, TLSA, VZ\n",
    "#predictionDate in form YYYYMMDD - 20190304"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPLIT BY DAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_df = df\n",
    "daysList = [];\n",
    "\n",
    "def createDayDF():\n",
    "    global new_df\n",
    "    day_df = pd.DataFrame(columns = ['timestamp','symbol','tradingDay','open','high','low','close','volume'])\n",
    "    currentDay = new_df.iloc[0]['tradingDay']\n",
    "    #print(currentDay)\n",
    "    \n",
    "    for index, row in new_df.iterrows():    \n",
    "        if row['tradingDay'] == currentDay:\n",
    "            day_df = day_df.append(row)\n",
    "            #print(index)\n",
    "            new_df = new_df.drop([index])\n",
    "\n",
    "    daysList.append(day_df)\n",
    "    \n",
    "while(not new_df.empty): #splitting up data by data and sorting it in an array \n",
    "    createDayDF()\n",
    "\n",
    "print(len(daysList))\n",
    "\n",
    "\n",
    "def getLastDayInTable():\n",
    "    print(daysList[-1].iloc[-1]['tradingDay'])\n",
    "    return daysList[-1]\n",
    "getLastDayInTable()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(30,10))\n",
    "\n",
    "\n",
    "for i in range(len(daysList)): \n",
    "    #print(daysList[i]) \n",
    "    plt.subplot(2, 9, i+1)\n",
    "    #plt.plot(x, y)\n",
    "    \n",
    "    plt.plot(daysList[i]['low'], 'b')\n",
    "        \n",
    "    plt.xlabel('TIMESTAMP')\n",
    "    plt.ylabel('PRICE')\n",
    "    plt.title('AAPL PRCIES ' + str(daysList[i]['tradingDay'].iloc[0])) \n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "copy_df = df\n",
    "daysList = [];\n",
    "weeksList = [];\n",
    "\n",
    "def createDayDF():\n",
    "    global copy_df\n",
    "    day_df = pd.DataFrame(columns = ['timestamp','symbol','tradingDay','open','high','low','close','volume'])\n",
    "\n",
    "    currentDay = copy_df.iloc[0]['tradingDay']\n",
    "\n",
    "    \n",
    "    for index, row in copy_df.iterrows():    \n",
    "        if row['tradingDay'] == currentDay:\n",
    "            day_df = day_df.append(row)\n",
    "            #print(index)\n",
    "            copy_df = copy_df.drop([index])\n",
    "\n",
    "    daysList.append(day_df)\n",
    "    \n",
    "    \n",
    "\n",
    "def createWeekDF():\n",
    "    week_df = pd.DataFrame(columns = ['timestamp','symbol','tradingDay','open','high','low','close','volume'])\n",
    "    print()\n",
    "    newWeekLength = 0 #used for days that the market is closed\n",
    "    for i in range(len(daysList)): \n",
    "        currentDay = daysList[i].iloc[0]['tradingDay']\n",
    "        currentDay_raw = currentDay.replace('-','')\n",
    "       # print((currentDay_raw))\n",
    "        dt = datetime.datetime(int(currentDay_raw[0:4]), int(currentDay_raw[4:6]), int(currentDay_raw[6:8]))\n",
    "       # print(dt)\n",
    "        #print(dt.weekday())\n",
    "        \n",
    "        \n",
    "        if (len(weeksList) == 0):\n",
    "            print(\"First week created - starting with \" , dt.weekday())\n",
    "            weeksList.append(daysList[i])\n",
    "            \n",
    "        elif (newWeekLength >= 5):\n",
    "            print(\"more then 5, new week - starting with \" , dt.weekday())\n",
    "            weeksList.append(daysList[i])\n",
    "            newWeekLength = 0\n",
    "        else:\n",
    "            if (dt.weekday() == 0): #monday new week\n",
    "                print(\"--------\")\n",
    "                print(\"Creating New week - day \", dt.weekday())\n",
    "                weeksList.append(daysList[i])\n",
    "                newWeekLength = 0\n",
    "            else:\n",
    "                print(\"adding to week\", dt.weekday())\n",
    "                weeksList[-1] = pd.concat([weeksList[-1],daysList[i]])\n",
    "                 \n",
    "            #0 = monday\n",
    "            #1 = tues\n",
    "            #2 = wed\n",
    "            #3 = thurs\n",
    "            #4 = fri\n",
    "        newWeekLength += 1\n",
    "        \n",
    "while (not copy_df.empty): #splitting up data by data and sorting it in an array \n",
    "    createDayDF()\n",
    "\n",
    "    \n",
    "createWeekDF()\n",
    "#print(weeksList[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,30))\n",
    "\n",
    "\n",
    "for i in range(len(weeksList)): \n",
    "    #print(daysList[i]) \n",
    "    plt.subplot(5, 1, i+1)\n",
    "    #plt.plot(x, y)\n",
    "    \n",
    "    plt.plot(weeksList[i]['close'], 'b')\n",
    "\n",
    "    plt.locator_params(axis='y', nbins=6)\n",
    "    plt.locator_params(axis='x', nbins=5)\n",
    "    \n",
    "    plt.xlabel('TIMESTAMP')\n",
    "    plt.ylabel('PRICE')\n",
    "    plt.title('AAPL PRICES FROM: ' + str(weeksList[i]['tradingDay'].iloc[0]) + \" TO \" + str(weeksList[i]['tradingDay'].iloc[-1])) \n",
    "    \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
